{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sacarsm detection.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chequanghuy/CS114.K21/blob/master/Sacarsm_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6hTecFwiMaH",
        "colab_type": "text"
      },
      "source": [
        "**Mô tả bài toán**\n",
        "Bài toán Sacarsm Detection áp dụng dùng nhận biết cảm xúc của một bình luận, một tiêu đề là tiêu cực hay tích cực hay trung lập. Trong bài toán này ta sẽ phân biệt xem tiêu đề của các bài báo mang tính chất là châm biếm hay không châm biếm. Các headline ở đây sẽ được thu thập từ các trang tin cậy như TheOnion-website luôn đăng các tin châm biếm và HuffPost-website chuyên không đăng các tin châm biếm. \n",
        "\n",
        "\n",
        "**Thu thập headline để làm testset**\n",
        "Thu thập bằng cách crawl data ở các hai trang TheOnion và HuffPost sau đó gán nhãn cho chúng là is_sarcastic hay non-is_sarcastic sau đó lưu ở dạng file json.\n",
        "\n",
        "\n",
        "**Xử lý dữ liệu, feature engineering**\n",
        "Trước tiên ta sẽ đưa các chuỗi về dạng chữ thường không viết hoa và loại bỏ các ký tự đặc biệt, sau đó vecto hóa chúng bằng Tokenizer của Keras\n",
        "\n",
        "\n",
        "**Chọn model, Training và fine tuning**\n",
        "Xây dựng một model với các lớp Embedding, LSTM và output gồm hai lớp là is_sarcastic hay non-is_sarcastic, lựa chọn loss function, optimizer cho phù hợp. Trong quá trình học ta sẽ tinh chỉnh các hệ số Dropout, learning rate, batch size, epoch,.. để phù hợp và tránh overfitting, underfitting. Ở đây có dùng Pre-Trained GloVe Embedding để thu được kết quả tốt hơn\n",
        "\n",
        "**Mô tả cách dùng model để sacarsm detection cho một headline bất kỳ**\n",
        "Ta cần xử lý dữ liệu và feature engineering trên chuỗi nhập vào như các chuỗi dùng để training sau đỏ dùng model đã train để dự đoán kết quả\n",
        "\n",
        "**Test performance của model đã train với khoảng 2000 headlines với thu thập được**\n",
        "Trong quá trình training thì kết quả đạt được độ chính xác sau 4 epochs trên tập dữ liệu training là 92%, tập validation là 87%, với bộ dữ liệu test (2000 headlines mới thu thập) là 81% \n",
        "\n",
        "**Nhận xét về bài toán**\n",
        "Đây là một bài toán vẫn đang gặp nhiều khó khăn nếu dùng nó để nhận xét bình luận của các trang mạng xã hội vì dữ liệu trên các trang mạng xã hội kh rõ ràng và các từ vựng cập nhập hằng ngày nên vẫn còn nhiều khó khăn đối với bài toán này ở thời điểm hiện tại\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TrTDzfTfXSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import os\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR9ZZGp7P9tc",
        "colab_type": "text"
      },
      "source": [
        "Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dtzDpJNgtBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPErkaelgzMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My Drive/Colab\\ Notebooks/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DPG8VAChTh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_json('./New-headline/Sarcasm_Headlines_Dataset.json', lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MTRchySQEgr",
        "colab_type": "text"
      },
      "source": [
        "Đọc file JSON dùng thư viện pandas và lưu dữ liệu ở dạng Data Frame. Đây là dataset đã cho sẵn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgCy0OU5xKko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test1 = pd.read_json('./New-headline/testNegative.json', lines=True)\n",
        "df_test2 = pd.read_json('./New-headline/testPositive.json', lines=True)\n",
        "frames = [df_test1, df_test2]\n",
        "df_test = pd.concat(frames,ignore_index=True)\n",
        "\n",
        "df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
        "df_test.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1apyS3kQWmT",
        "colab_type": "text"
      },
      "source": [
        "Đưa testset về DataFrame sau đó xáo trộn dữ liệu Positive và Negative\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50D6hWgTsNO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot(df.is_sarcastic)\n",
        "plt.xlabel('Label')\n",
        "plt.title('Sarcasm vs Non-sarcasm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJyxXVLS8Poc",
        "colab_type": "text"
      },
      "source": [
        "Thống kê dữ liệu Sarcasm và Non-sarcasm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yV9I7wO2Pt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot(df_test.is_sarcastic)\n",
        "plt.xlabel('Label')\n",
        "plt.title('Sarcasm vs Non-sarcasm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abiVkAABQuFJ",
        "colab_type": "text"
      },
      "source": [
        "Thống kê dữ liệu Sarcasm và Non-sarcasm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kcqvraMwXDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['headline'] = df['headline'].apply(lambda x: x.lower())\n",
        "df['headline'] = df['headline'].apply((lambda x: re.sub('[^a-zA-Z0-9\\s]','',x)))\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFQRTkFf8TyW",
        "colab_type": "text"
      },
      "source": [
        "Chuyển hết chữ hoa thành chữ thường\n",
        "Loại bỏ hết các ký tự trừ các ký tự từ a-z, A-Z, 0-9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf1enhWR42HA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test['headline'] = df_test['headline'].apply(lambda x: x.lower())\n",
        "df_test['headline'] = df_test['headline'].apply((lambda x: re.sub('[^a-zA-Z0-9\\s]','',x)))\n",
        "\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ac2IEInTD6L",
        "colab_type": "text"
      },
      "source": [
        "Chuyển hết chữ hoa thành chữ thường\n",
        "Loại bỏ hết các ký tự trừ các ký tự từ a-z, A-Z, 0-9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9We8_N4pyd-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['totalwords'] = df['headline'].str.count(' ') + 1\n",
        "Max_len1=df['totalwords'].max()\n",
        "df_test['totalwords'] = df_test['headline'].str.count(' ') + 1\n",
        "Max_len2=df_test['totalwords'].max()\n",
        "Max_len=max(Max_len1,Max_len2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-zlxLc9TbLN",
        "colab_type": "text"
      },
      "source": [
        "Tìm số từ lớn nhất có mặt trong các chuỗi.\n",
        "Đây sẽ là input_length của Embedding Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGaLpWksCP8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['headline'].values)\n",
        "#max_features = len(tokenizer.word_index) + 1\n",
        "tokenizer.fit_on_texts(df_test['headline'].values)\n",
        "max_features = len(tokenizer.word_index) + 1\n",
        "# integer encode the documents\n",
        "X = tokenizer.texts_to_sequences(df['headline'].values)\n",
        "X = pad_sequences(X, maxlen = Max_len)\n",
        "Y = pd.get_dummies(df['is_sarcastic']).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bu6nF5KFA3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = tokenizer.texts_to_sequences(df_test['headline'].values)\n",
        "X_test = pad_sequences(X_test,maxlen=Max_len)\n",
        "Y_test = pd.get_dummies(df_test['is_sarcastic']).values\n",
        "Y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Np8xGtbVC9S",
        "colab_type": "text"
      },
      "source": [
        "Sử dụng Tokenizer để vector hóa các chuỗi, max_features là số lượng các từ khác nhau có trong tất cả các headline, X sẽ là các vector sau khi vector hóa các chuỗi headline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9ogEHGdHxa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "embeddings_index = dict()\n",
        "f = open('./weight/glove.6B.200d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "embedding_matrix = zeros((max_features, 200))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1pVXDRioEmw",
        "colab_type": "text"
      },
      "source": [
        "Sử dụng Pre-Trained GloVe Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4V_4qO77CKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size = 0.2, random_state = 42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-BkvqhmoXCr",
        "colab_type": "text"
      },
      "source": [
        "Tách dữ liệu thành 2 phần training và validation, 20% cho validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1grWR0qs7Iy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_dim = 200\n",
        "lstm_out = 196\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_dim,weights=[embedding_matrix],input_length =Max_len))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1931_zlMniEh",
        "colab_type": "text"
      },
      "source": [
        "Xây dựng model, với Embeddeing layer sẽ có input_length=Max_len, output_length =200 do sử dụng Pre-Trained GloVe Embedding với số chiều là 200. Sau khi qua Embeddeing layer ta sẽ qua SpatialDropout1D để dropout dữ liệu. Sau đó qua LSTM để học đặc trưng của chuỗi. Output sẽ là 2 lớp. Sử dụng loss là 'categorical_crossentropy', optimizer là 'adam' "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJdPGAoW7Ln1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "num_of_epoch=4\n",
        "history = model.fit(X_train, Y_train,validation_data=(X_val, Y_val), epochs=num_of_epoch, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5gMUiq90pVh",
        "colab_type": "text"
      },
      "source": [
        "Train data với epochs=4, batch size =32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbubSfbKVjaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
        "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
        "ax1.set_xticks(np.arange(1, num_of_epoch, 1))\n",
        "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
        "\n",
        "ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "ax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "ax2.set_xticks(np.arange(1, num_of_epoch, 1))\n",
        "\n",
        "legend = plt.legend(loc='best', shadow=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOeyZgMb0xtW",
        "colab_type": "text"
      },
      "source": [
        "Vẽ biểu đồ của acc và loss trong quá trình training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBNyL5U-MU-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss,acc = model.evaluate(X_test, Y_test)\n",
        "print(\"loss: %.2f\" % (loss))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRcZLDLbJg0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My Drive/Colab\\ Notebooks/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT8NXsM5JiVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/chequanghuy/CS114.K21.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmv9vyCm6s3b",
        "colab_type": "text"
      },
      "source": [
        "Đánh giá model trên tập dữ liệu test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO7iYZ-8H4-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/CS114.K21"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oMHLjmfNzyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git checkout master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jko7WlP9IFcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git add *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd2O-sR7OF3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6-OkHIlKTSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git commit -m \"case study\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qwHtIG1KcGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git config --global user.email \"quanghuy6999@gmail.com\"\n",
        "!git config --global user.name \"chequanghuy\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBomIRBwLQkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git remote add origin https://chequanghuy:$01218619046Huy@github.com/chequanghuy/CS114.K21.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ppal9iUNDMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git remote rm origin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGPTYj2kKfRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git commit -m \"case study\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZuaIylGKqta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git push origin master "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ow8p27bTNs9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}